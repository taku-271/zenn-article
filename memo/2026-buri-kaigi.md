2025年
The End of Programming as We Know It -> オライリーの立ち上げ者がいった
Vibe Coding -> ノリでプログラミング -> 70%問題 残り3割を仕上げるのが難しい
Ai Slop -> もっともらしい出力になる -> 他者へのレビューコストが上がる -> 今もそう
FOMO: Fear of Missing out, 乗り遅れる恐怖感に苛まれる -> AIの進化が激しいため、乗りこなすのが難しい -> 一旦落ち着きながら使っていきましょう -> どう使うのか

Vibe Coding -> Agentic Coding -> ちゃんとAIでコーディングしようkj:w
SDD -> kiro, spec kit -> 仕様駆動開発 -> 実力差を縮めるツールなのではないか
Vibe Codingは自分が欲しいソフトウェアを自分で作れることが最も大きい -> 他者へのソフトウェアには（少なくとも今は）まだ向いていない
プロが求められる技術はもっと大きくなる

Discovery -> 正解を探すもの -> Vibe Codingで行えるため、使わない手はない -> 歴史上、これとプログラミングがここまで近いのは今までなかった
Delivery -> 提供するもの -> 大奥の人が使うソフトにはまだ課題がある -> 本日の課題

AI/LLMの
LLMの登場は高水準プログラミング言語への移行と同じくらい大きく変える
抽象化レベルの向上だけではなく非決定性という横方向にも進む　-> 前例がない
非決定性を決定性にして再現性があるもの -> AIによって非決定性が発生

LLMはもっともらしく見えるが、その確信部分は単に次の単語を予測するモデルにすぎない -> LLMのプロンプトエンジニアリングがCopilotを作った人が書いた本で、とてもリアリティ
**ハルシネーションはバグではなく機能**。模倣エンジンの必然的帰結 -> 私たちが解決しているから気にならなくなってきている

非決定性は機能。AIエージェントにいうことを聞かせようとするアことを聞かせようとするアプローチには限界がある
いうことを聞かなくても問題ないようなアプローチを行うことで工学的にも精神衛生的にも良い -> うまくいかずハラスメントにならない
ソフトウェア開発を「部分的に確率的に間違っても仕組みで気づけるプロセス」 -> 人間が頑張るではなく仕組みで気づけるにしないと辛い

AIの時間と複雑さのグラフ -> 複数のエージェントをオーケストレーションし出して、複数のスラッシュコマンド -> この流れはAIエージェントに任せる
最終的に中規模の指示を出して見守るものになる

生成AIのコードは保守できないからダメ -> 人間がコードを読まなくてもわかる状況をどう作るかになってきている
-> 似ている構図 -> 大規模開発のアーキテクトが直面してきたものを見る
-> 適応度関数で調査、促進したい品質、制約、機能要件からアーキテクチャを選ぶ

適応度関数 -> メトリクス測定と判断がセットになったもの
-> カバレッジの継続的かんし、閾値範囲
-> 複雑度
-> レイヤーの依存方向の定義と違反
-> 4keys

単一メトリクスはハックされる -> AIは簡単にハックしてくる
グッドハートの法則：ある指標が目標だとその指標は目的を失う

ハックすると他の指標が落ちるような牽制し合う複数のメトリクスを図る
**人間に求められるのは牽制し合うことで全体が良い方向に進むメトリクスの組み合わせとその適応度関数の設計**
-> カバレッジだけだとハックされるので、Code Test Ratioと組み合わせる

2024年の自動テスト
-> 信頼性の高い実行結果に短い時間で到達する状態を保つ -> 開発者に自信を持たせる -> ソフトウェアの成長を持続可能にする
2025年の自動テスト
-> AIに根拠ある判断基準を与え、ソフトウェアの成長を持続可能にする

architecture as code -> ADL: Architecture Definition Lnguage（疑似コード） -> AIに読ませることで各言語の適応度関数を生成できる
疑似コードから実行可能なプログラミングにすることでCIに組み込むことができる
レイヤーの違反を判断する -> これめっちゃいいな

クラス、コードが満たすべきちょうどいい抽象度との距離 -> これもAIが作成できる

従来の構図 -> 理解容易性と変更用意性はトレードオフだった -> どこからか枝分かれするタイミングがあるはず
AIの構図
-> 変更者が人間からAIに置き換わる
-> 変更に対する許容量が人間とAIで違う -> 冗長なコードでもAIは修正できる
-> 理解容易度は人間もAIもそこまで変わらない -> AIには読めるけど人間には読みにくいコードはない
-> トレードオフが緩和され、理解容易性への投資が活きる -> どちらを取るかになったら読みやすさを優先できる
変更用意性に寄与する技法の再評価が必要
-> AI時代にSOLIDは同じなのか -> SIDは重要度が上がる -> OLは下がることがありうる

人間の認知負荷の低減 -> AIのコンテキスト効率向上
意図を伝える識別し、狭いスコープ、小さな関数、明示的な依存関係
実行次の柔軟性より静的で明示的な解析性を好む
適切な抽象化を行う
ユビキタス言語と境界づけられたコンテキスト
ドメイン駆動開発が大事になりそう
**コードの近くにあり保守されているドキュメントが大事**

上記の価値観を人間とAIで共有し、その促進や仕組み化を行う
-> 「そこになければないですね」を目指す -> 探索を打ち切ることができる状態が大事

人が行う前提だったプラクティスのコスト構造を再確認する
-> 重要×非緊急の証言に馬力を出せる
-> 従来コスパの観点で避けられてきたプラクティスに光をあてる
手動テストから自動テストのシフト
-> これまで自動化で起こったのは実施コストの大幅な低減による変化
-> 少ないテストで多くのものをテストするのが良かった
-> 今度は記述・変更コストの大幅な低減が起こっている
-> 記述・変更コストが減ると、検証、所有、記録コストが減る

望ましいがコスパ悪いのが射程に入ってくる
コードカバレッジ100%はアンチパターンではなくなる
力押しのテストケース全網羅も選択肢になる
Property Based testing（PBT）
Consumer Driven Contract Testing -> 誰がメンテするのか、学習コストが高かったものをAIと共にできる
形式手法やモデル検査 -> Prediction: All will make formal verification go mainstream
アクセシビリティへの投資が複数の品質特性に効く

確立的なツールなので、検証は確定的でないといけない
-> 速度、決定性、独立性を高める
-> ユニットテストを多く描き、E2Eテストはそこまで書かない
-> 作る対象が確立的な場合は検証も確立的になってしまう -> EDD

生成の段階が深くなるほどレバレッジが効く
-> Aiがテスト実施のみ
-> AIがテストコード生成
-> AIがテスト生成コードを生成

Aiの非決定性と創造性は**探索的テストにこそ活きる** -> これまで見えてなかったバグを見つけだす
-> 従来人間にしかできなかったテスト領域への進出も大きなインパクト

車輪の再開発はあく
-> 小さなライブラリは所有させるのも良い

ローカルでのFake実装も可能になる
-> 外部チームなどが開発したものをモック化する
ドキュメントを各工数が減った
-> ドキュメントを書く動機と利益もできた

Aiがドキュメント変更を行うこともできる

Convertional Commits
Keep a Changeling
ADR: Architecture Decision Record
などの少ない単語の名前を知ることで小さな言葉で使える

LLMには知識はあるが知恵がない

LLMの非決定性の動作を受け入れ、仕組みで支える
AIツールをカスタマイズするのではなく、決定性がありスケールする仕組みをAIに生成させよう
コストを前提にしていたプラクティスをAIによる生産性とコスト構造で思考しよう

# Day1 AIで急増した生産「量」の荒波をCodeRabbitで乗りこなそう
キャラクターの名前はHoppy
独自のアプリケーションを作れない
理想はAIが開発してコーヒーを飲みたい音楽を聴きたい

コードの責任はあくまでユーザーにある -> code rabbitはレビューする前の1次レビュー
コードレビューは第三者の視点で、品質、可読性、保守性、安全性を高めるプロセス
チームがより良いコードを書くための、学習・共有・品質保証の仕組み
プロダクトの品質を保証するものではない -> QAはテストで行う

コードレビューのガイドラインの有無 -> 一定の基準を設けるようにする

職級、経験が上の人がチェックする
-> 1番上が書いたら誰がするのか
レビュー通過＝不具合なし
-> バグなしはテストの役割
設計思想を詰められる
-> PR提出を委縮し、心理的安全性を損なう

これらの問題がある
    レビューがシニアエンジニア、CTOの役割になってしまっている役割になってしまっている
    職種が上だとタスクも多い。レビューまで加わる
    ミーティングや外出でレビューが止まる
    
レビューがボトルネックになるのは問題

シニアエンジニアがAIのコードをレビュー
-> Aiコーディングは割と力押しの場合もある
-> コピペ問題
-> 責任の所在
-> AIのコードに対してレビューするのは、コーディングエンジニアの価値がない
-> 自身のコードを保証できるのかどうか

レビューの自走割り当て
-> 順番に割り当て、負担をバランシングする
-> ラウンドロビンアルゴリズム、ロードバランスアルゴリズム

ガイドラインを策定し、属人化しない
-> レビューの視点、無視すること、確認することを定義
-> レビューを受ける側のガイドラインも重要
-> https://fujiharuka.github.io/google-eng-practices-ja/

レビューの目的とゴールを明確化し、時間と労力を防止

小さなPR -> 500行にする（アドベントカレンダー）
優先度の設定 -> アーキテクチャ、データベーススキーマの変更は厳重
レビュー時間の確保（開発タスクの低減）
AIコードレビューの導入

従来のレビュー -> 全ての変更を確保、共有する
今後のレビュー -> リスクの評価と自動化で品質を保証

# Day1 TDD BootCamp
DataProvider
