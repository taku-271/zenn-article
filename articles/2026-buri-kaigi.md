---
title: "2026ブリ会議に参加しました！"
emoji: "👻"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: []
published: false
publication_name: "uniformnext"
---
# はじめに
最近色々なイベントに参加することで視野が広がりつつ、卒論がやばいなと感じているたくみです。
先日開催されたブリ会議2026の1日目のみ参加したのでその内容をまとめます。
https://burikaigi.dev/

来年は2日間参加することを目標にしています。

# Day1 基調講演 2026年のソフトウェアエンジニアリング
https://fortee.jp/burikaigi-2026/proposal/22dcc885-d47d-4615-a42f-428b48c21a38
[和田卓人](https://x.com/t_wada)さんの基調講演でした。
2025年の振り返りと2026年、AIとどう向き合ってエンジニアリングしていくかという内容でした。以下、内容をまとめました。
## 2025年の振り返り
### AIコーディングに対する振り返り
2025年に`Vibe Coding`というものが出てきましたが、これは70%の問題を解決でき、30%の問題を解決することが難しいと言われています。また、AIはもっともらしい出力を出すので、レビューコストが上がっています。また、`Vibe Coding`で作成したソフトウェアは、自分が欲しいものを作ることに対しては有効だが、他者へのソフトウェアにはまだ向いていません。
これらの理由から`Vibe Coding`に変わって`Agentic Coding`というものが出てきました。これにより、ノリではなくちゃんとAIを使ってコーディングしようという流れができてきました。

## 2026年のエンジニアリング
### AI/LLMの前提
AI/LLMの登場は、機械語や低水準プログラミング言語から高水準プログラミング言語への移行と同じくらい、エンジニアリングを大きく変えると言われています。
また、今までにはない非決定性という性質を持っています。つまり、AIに決定性や再現性を求めるのは難しいとなっています。
これは、LLMの核心は単に次の単語を予測する（マルコフ連鎖）モデルであり、その確率性をなくすことはできないためです。そのため、**ハルシネーションはバグではなくAI/LLMの仕様**と言えます。

### AIの非決定性をどうするか
非決定性は仕様なので、AIにいうことを聞かせようとするアプローチには限界があります。うまくいかずにハラスメントになるという経験をした方々も多いと思います。そのため、AIがいうことを聞かなくても問題ないようなアプローチを行うことで、工学的にも精神的にも良いと言えます。
今後は、ソフトウェア開発で「部分的に確率的に間違っていても仕組みで気づけるプロセス」を考えないといけません。
また、AIの非決定性は**探索的テスト**にとても活きます。この非決定性によってこれまで見えなかったバグを見つけ出すことができます。

### AIのコードの保守
AIが生成したコードの保守って結構大変だと思います。現状、人間がコードを読まなくても良い状況をどう作るかというアプローチに変わってきています。
これは、大規模開発のアーキテクトが直面してきた問題に似ています。大人数のエンジニアが同じコードを書き、全てのコードを理解している人はいないと思います。
大規模開発においては、適応度関数を作成し現状を調査、品質や制約、機能要件をもとにアーキテクチャを決定し、保守しやすいコードを作っていくというアプローチが使われています。AIのコードにも同じことをすることで保守しやすいコードができるのではないかと考えられます。

#### 適応度関数
ここで出てくる適応度関数とは、**メトリクス測定と判断がセット**になったもので、以下のようなものが例として挙げられます。
* テストカバレッジの監視、閾値範囲を設定
* 複雑度の監視、閾値範囲を設定
* レイヤーの依存方向の定義と違反を監視

単一のメトリクス、単一の適応度関数を使用すると人やAIはハックしようとします（グッドハートの法則）。
ハックすると他の指標が落ちるような牽制し合う複数のメトリクスを作ることで、このグッドハートの法則を対策することができます。

### 自動テストと適応度関数
自動テストは適応度関数の一種です。
2024年の自動テストは、信頼性の高い実行結果に短時間で到達する状態を保ち、ソフトウェアの成長を持続可能にするものでした。
2025年の自動テストは、AIに根拠ある判断基準を与え、ソフトウェアの成長を持続可能にするものだったと言われています。
例えば、オライリーの`Architecture As Code`に載っている、`ADL: Architecture Definition Language`を疑似コードとして作成し、AIに正しいアーキテクチャの判断基準として読み込ませておくことで簡単に適応度関数を生成することができます。疑似コードから実行可能なプログラミングにすることでCIに組み込むことも可能になります。

### ソフトウェア開発で重点を置く部分
ソフトウェア開発をする上で、従来は理解容易性と変更容易性はトレードオフの関係でした。突き詰めていくと、最終的にどちらかに枝分かれをするはずです。
AIが出てきた今後、コードの変更者がAIに置き換わることで、変更に対する許容量が大幅に向上しするため、理解容易性への投資を大切にする方が良いです。変更用意性はAIに24 365で働いて貰えば良いということです。
この重点の変化によって、変更容易性を重視する技法の再評価が必要になります。例えば、`SOLID`について、`SID`は重要度が上がるが、`OL`は下がることがありうるということが発生します。

### AIのコンテキストとドキュメント
`SDD`などではAIとの認識合わせにドキュメントを多く使います。AIと共にドキュメントを整備していくため、ドキュメントを書く工数が減り、ドキュメントを書くことで良いリターンが返ってくるようになりました。
また、そのプロジェクトのドキュメントはできる限りコードの近くにおき、ちゃんと保守することが大事です。AIがドキュメントを探しにいった時に、「そこになければない」という状況、つまり、探索を打ち切ることができる状態が大事になっています。

### AIが担当する領域
従来は人が開発を行う前提だったため、コストの観点から避けられていたタスクも行えるようになりました。
例えば、重要ではあるが非緊急のタスクは、リソースが限られていると後回しにされてしまいます。しかし、AIがここにフルコミットすることで、今まで後回しにしていたことが進みます。
また、自動テストをAIに実装してもらうことで、自動テストへのコストが大幅に減ります。従来はできる限り少ないコード、テスト量で多くのケースを拾うことがベストプラクティスでした。しかしAIに自動テストを任せることで、カバレッジ率100%がアンチパターンではなくなるかもしれません。

### AIの知識量を使いこなす
「LLMには知識はあるが知恵がない」という言葉があります。
AI/LLMには膨大な知識量がありますが、それらの知識を引き出すスキル（知恵）は持っていません。
いかに私たちがその知識を引き出せるか、的確にその内容を伝え、使ってもらうのかが大事になります。
私たちも学習を怠ってはいけない理由です。

## まとめ
* LLMの非決定性は受け入れ、仕組みで支える
* AIツールをカスタマイズするのではなく、決定性がありスケールする仕組みをAIに生成させよう
* コストやリソースを前提にしていたベストプラクティスをAIによる生産性とコスト構造で乗り越えよう

## 感想
とても聞き入ったセッションでした。共感できる部分が多くあり、私たちが普段持つ疑問に対して、一つ一つ誘導され解答を作成してる気分でした。
AIの圧倒的な生産量と非決定性という性質を活かし、AIパワハラを行わないようにしていきたいです笑。
`ADL`や依存方向性などの疑似コードを作成する案はとても良いなと思ったので是非とも導入したいなと感じました。

# Day1 AIで急増した生産「量」の荒波をCodeRabbitで乗りこなそう
https://fortee.jp/burikaigi-2026/proposal/e8102300-256d-4f61-9f20-187adafdc5bb
[中津川篤司](https://x.com/goofmint)さんのスポンサーセッションでした！
ちょうどCodeRabbitを使っていますし、生産量が増えてきてレビューがパンクしそうだったという共感を持ったので聞きました。以下、内容をまとめます。

## キャラクターの名前
CodeRabbitのキャラクターの名前は**Hoppy**らしいです。
これだけ覚えて帰ってくださいと言われました笑。

## AIコーディング
最近、AIコーディングが流行ってきていますが、独自のアプリケーションの作成はまだまだ難しく、AIが開発してエンジニアは音楽を聴きながらコーヒーを飲むといった優雅なコーディングはまだまだ先になりそうです。

## レビュー
AIを使用したとしても、コードの責任はあくまでユーザーにあります。そのため、CodeRabbitはエンジニアがレビューする前の1次レビューとして使うのがおすすめです。